---
title: "AI Evolution: Weekly News Digest"
date: 2023-06-18
mathjax: true
toc: true
categories:
  - blog
tags:
  - pytorch
  - news
---


# Introduction
AI is revolutionizing various aspects of our daily lives, with new applications and advancements emerging every week. Here's a roundup of some of the most impactful and intriguing AI news from the past week.

# Chatbots in the Classroom
In a groundbreaking move, certain US primary and secondary schools are testing an automated tutor called 'Khanmigo', built by online educator Khan Academy. Based on the GPT-4 architecture, the bot challenges students by replying to queries with questions, fostering critical thinking. Integrated with the Khan Academy’s previous tutoring software, it aids students in vocabulary practice, creative writing, debates, and even in navigating university admissions and financial aid. While some educators fear it may encourage cheating or spread misinformation, others see it as an invaluable 24/7 learning resource.
# Training Data Free-For-All in Japan

In a striking legislative decision, Japan has given the green light for AI developers to train models on copyrighted works, a move that has sparked debates about fairness and copyright laws. This law permits developers to use copyrighted works for commercial purposes, which is quite unique globally. As the G7 countries strive to create mutually compatible regulations for generative AI, Japan's stance could influence the direction these policies take.

# Image Generation Becomes Swift with Paella
A new system, Paella, developed by Dominic Rampas and colleagues, leverages diffusion processes to generate high-quality images swiftly. By utilizing tokens from a predefined list, the number of steps needed for image generation is greatly reduced, making the process quicker without sacrificing quality. This technique could pave the way for a host of applications, from engineering to entertainment.

# Google's Confidentiality Concerns with Chatbots
In light of potential information leaks, Google has advised its employees against entering confidential information into chatbots like OpenAI’s ChatGPT or Google’s own Bard. It highlights the security concerns related to AI, prompting an essential conversation about data privacy and confidentiality in the age of AI.

# Self-driving Cars: Motion Prediction Improves
The research into self-driving cars is far from over. Waymo has showcased how diffusion models can be used to predict distributions of motion for multiple “agents” on the road. This innovation improves performance over physics-based methods and other neural algorithms, nudging us closer to the reality of self-driving cars on our streets.

# Fine-tuning Large Models Becomes More Accessible
A significant development in the field of AI is the advancement of Low Rank Adaptation (LoRA), a task-specific and model-specific module used for fine-tuning large models. The improved LoRA enables fine-tuning on relatively inexpensive hardware, thus democratizing access to sophisticated AI capabilities.

# Research Section: FinGPT: An Open-Source Framework for FinLLMs
In response to the aforementioned challenges and in pursuit of democratizing FinLLMs, we present FinGPT. A data-centric, open-source framework, FinGPT aims to provide a robust and comprehensive solution for the development and application of FinLLMs.

4.1 Data Source Layer

As a starting point, we put forward the data source layer, which ensures thorough market coverage. In consideration of the temporal sensitivity of financial data, this layer is designed to provide real-time information capture from various sources, including financial news, company filings and announcements, social media discussions, and financial trends. This rich collection of diverse data types allows FinGPT to provide multi-faceted insights into the financial landscape.

4.2 Data Engineering Layer

The next layer in the FinGPT framework is the data engineering layer. Primed for real-time NLP data processing, this layer grapples with the inherent challenges of high temporal sensitivity and low signal-to-noise ratio in financial data. The data engineering layer involves comprehensive data cleaning, preprocessing, and formatting to ensure the quality and usefulness of the financial data fed into the subsequent layers of the FinGPT framework.

4.3 LLMs Layer

Building on the previous layers, we introduce the LLMs layer, which focuses on the implementation of a range of fine-tuning methodologies for the LLMs. Recognizing the highly dynamic nature of financial data, this layer prioritizes keeping the model's relevance and accuracy up-to-date, ensuring that FinGPT maintains its ability to provide accurate and actionable insights.

4.4 Application Layer

The final layer of the FinGPT framework is the application layer, which showcases practical applications and demonstrations of FinGPT in the financial sector. This layer provides concrete examples of how FinGPT can be utilized in various contexts, such as robo-advising, algorithmic trading, and low-code development. It serves as a testament to FinGPT's potential to revolutionize financial operations and decision-making processes.

5 Paper Conclusion

Through our development of FinGPT, we aim to foster a thriving, open-source ecosystem for financial large language models (FinLLMs). We hope that this framework will stimulate further innovation in the finance domain, facilitate the democratization of FinLLMs, and unlock new opportunities in open finance. By championing data accessibility and transparency, FinGPT is positioned to reshape the understanding and application of FinLLMs in financial research and practice.

```python
Data Preparation for Price Data and Tweets
First, we fetch price data and Tweets data from stocknet-dataset
Second, we input Tweets data to a GPT model, say "text-curie-001" or "text-davinci-003", and get the corresponding sentiment scores
Third, we save the sentiment scores to a file under ./data
```

```python
ChatGPT Trading Agent
We calculate the average sentiment score S.

We implement a simple strategy that buys 100 shares when S >= 0.3 and sells 100 shares when S <= -0.3

Parameters of GPT Model are:

"model_name": "text-davinci-003",  # "text-curie-001","text-davinci-003"
"source": "local",                 # "local","openai"
"api_key": OPEN_AI_TOKEN,          # not necessary when the "source" is "local"
"buy_threshold": 0.3,              # the max positive sentiment is 1, so this should range from 0 to 1 
"sell_threshold": -0.3             # the min negative sentiment is -1, so this should range from -1 to 0
```

```python
Backtest
We backtest the agent's performance from '2014-01-01' to '2015-12-30'.

Parameters are:

"stock_name" : "AAPL",        # please refer to the stocks provided by stocknet-dataset
"start_date":"2014-01-01",    # should be later than 2014-01-01
"end_date":"2015-12-30",      # should be earlier than 2015-12-30
"init_cash": 100,             # initial available cash
"init_hold": 0,               # initial available stock holdings
"cal_on": "Close",            # The column that used to calculate prices
"trade_volumn": 100,          # Volumns to trade
```

```python
The result is shown as follows:
```

<img src="https://camo.githubusercontent.com/6e766e35f5e4da1ef0b077b96864e027ccf7fdc4538d7cbb3c30cad7a49c0d47/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f6f6c6976657277616e6731352f696d67626564406d61696e2f696d672f3230323330323138313535383739362e706e67" width=500>

```python
The performance metrics are as follows
metrics	result
Annual return	30.603%
Cumulative returns	66.112%
Annual volatility	13.453%
Sharpe ratio	2.06
Calmar ratio	4.51
Stability	0.87
Max drawdown	-6.778%
Omega ratio	2.00
Sortino ratio	4.30
Tail ratio	1.84
Daily value at risk	-1.585%
Alpha	0.24
Beta	0.31
```

# Conclusion
As AI continues to evolve at a rapid pace, it is more important than ever to stay informed about the latest developments and discussions. The articles featured in this week's AI Evolution: Weekly News Digest provide a glimpse into the diverse and transformative applications of AI.

From the integration of chatbots in classrooms to the implications of training data free-for-all in Japan, these stories shed light on the opportunities and challenges presented by AI. The advancements in image generation, motion prediction for self-driving cars, and the democratization of fine-tuning large models further emphasize the progress we are making.

Moreover, the introduction of FinGPT as an open-source framework for FinLLMs opens up new possibilities in the financial domain, fostering innovation and accessibility. It holds the potential to revolutionize financial research and decision-making processes, making them more inclusive and transparent.

By staying up-to-date with these developments, I can actively participate in shaping the future of AI.




